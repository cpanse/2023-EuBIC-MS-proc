\section{Hackathons}

During the subsequent days, the participants split up into small groups to actively develop bioinformatics applications. Project proposals for the hackathon sessions were crowd-sourced in a transparent and open process \url{https://github.com/eubic/EuBIC2023/issues} prior to the meeting, community members could submit project proposals for hackathon sessions, which were subsequently evaluated on scientific merit and community interest.


\subsection{Maximilian Strauss - DeepScore: Community curated scoring, supercharged with AI}

State of the art for identification in mass-spectrometry-based proteomics is to generate “non-sense”, decoy data and to determine a score cutoff based on a false discovery rate. Nowadays, machine (ML) and deep learning (DL) algorithms are used to learn how to optimally distinguish targets from decoys. While this drastically increases sensitivity, it comes at the cost of explainability, and human-chosen acceptance criteria are replaced with black-box models. This can hinder acceptance in clinical practice, e.g., in peptidomics, where upregulated proteins are investigated by investigating raw data peaks. While other DL-driven domains allow straightforward human validation of the models, e.g., imaging, speech, text, or inspecting a predicted structure from AlphaFold, for proteomics, this is much more challenging. Here, we aim to explore the limitations of the current scoring approach and provide potential solutions. We revisit the idea of confidence by trying to artificially increase identifications with non-sense features, hard decoys, or leaking data. Next, we will build an interactive tool to validate identifications manually and assign human confidence scores. With this, we create a training dataset and build an ML or DL- model to rescore identifications and assign predicted human-level confidence scores.\\
\GHI{14}
%https://github.com/EuBIC/EuBIC2023/issues/14)


\subsection{Matthias Mattanovich/Muyao Xi - MS2 spectra matching for metabolite identification}

One major open topic in untargeted metabolomics is identifying unknown compounds from mass spectra. As MS1 comparisons can be ambiguous (especially for small molecules), we need to look at MS2 spectra, and compare them to public MS2 databases, to differentiate compounds in the same mass range. Currently, the best performing methods for compound identification are GNPS and Sirius. They provide a user with a list of potential compounds, but in some cases the uncertainty is very high or multiple candidates are suggested, making the downstream analysis labor intensive. GNPS improves their predictions by using molecular networks and taking biological information into account[a]. Sirius improves their predictions by comparing structural similarity of the compounds. We would like to set up a novel system, with modular parts that can be tested separately. Each aspect of the pipeline can be improved/modified individually, and multiple methods can be combined as an ensemble. In doing so, this can also serve as a benchmark of existing scoring and matching functions and a testing playground for novel ideas.\\
\GHI{13}

\subsection{Ludwig Lautenbacher - Shaping a European prediction service for biological data}

We developed Koina (see \url{http://koina.proteomicsdb.org/}, \citep{Lautenbacher2024}), an open-source and modular machine learning (ML) inference server for biological data based on NVIDIA Triton. This platform allows centralizing the hosting of models originating from various training/prediction pipelines such as PyTorch, Sklearn, XGBoost and TensorFlow. Most importantly, models can be accessed by a remote and language-independent interface. A similar system has been used for the last 5 years within Skyline (C\#), the Prosit website (Python), and ProteomicsDB (JavaScript) to access Prosit models. We envision that such a platform will be centrally hosted by, for example, the EBI, and model submission will become a standard practice for publishing new ML models. Although accompanying codebases on platforms like GitHub describe the access of models, they require technical skill to set up. Standardizing the access of the models will dramatically improve reproducibility, and ensure easy access for as many people as possible.
As part of this Hackathon, we successfully extended our high-performance prediction service, named Koina, by adding multiple machine-learning models from the DeepLC \citep{pmid34711972}, MS2PIP \citep{pmid24078703, pmid25990723}, AlphaPept \citep{pmid36433986} and Prosit \citep{pmid31133760, pmid35549156, pmid34099720} ecosystems. Since then, we have established a common interface between all these models, enabling the seamless generation of predictions with all models.\\
\GHI{12}


\subsection{Matthew The - Easy-to-use interactive HTML plots collection for data exploration and web tools}

Interactive data exploration and publicly accessible web applications for bioinformatics tools are an essential part of bioinformatics. Ideally, one uses the same framework for both to reduce development time. Shiny apps are popular for this purpose, but are limited to the R language, while Python’s interactive plotting solutions (Plotly, Bokeh) tend to have a steep learning curve and are tricky to deploy. For ProteomicsDB \url{https://www.proteomicsdb.org/}, we developed over a dozen interactive, general-purpose plots based on D3.js and Vue.js \url{https://github.com/wilhelm-lab/proteomicsdb-components}. These range from simple scatter and bar plots to interaction graphs, heatmaps and pathway viewers. We managed to easily reuse and adapt these components in ongoing projects, allowing quick deployment upon publication.For the hackathon, we propose releasing these plots as Web Components \url{https://www.webcomponents.org/introduction}, the HTML standard that will shape the web for the coming decade. Web Components are easily includable in web pages as simple HTML tags without JavaScript knowledge. As this is purely a frontend framework, data processing and provisioning can be done in any programming language. We aim to provide examples and documentation to make integration for bioinformaticians easy and straightforward in any project.\\
\GHI{11}


\subsection{Dirk Winkelhardt - Rusteomics - Community driven toolbox for omic-research}

The proteomics community created some exceptional toolboxes over the past years, like OpenMS, Pyteomics or mzR. Most of these toolboxes implement general computational tasks, like reading and preprocessing data. However, most of them do not rely on a mutual code base or the same internal data representation, which makes interoperability only possible by using (PSI) standard formats. Reading/writing them without a common implementation may introduce another layer of errors.
The aim of Rusteomics is to build a collaborative community-driven toolbox, which provides read and write access to the most common file formats, as well as low-level and well established algorithms like (deisotoping, deconvolution, MS/MS spectra annotation, etc.).
While similar solutions exist in various programming languages, this project will be the opportunity to tailor these new components to be highly compatible with scientific (scripting) languages like Python / R. Moreover, the reimplementation in Rust should bring some major benefits: The modern compiler and building system makes Rust-based projects easier to maintain than C++-based projects, while providing the same performance.
During this hackathon, we will refine the goals/organization of the project, and start the development of a tool that can be used to generate spectral libraries (MSP format writer).\\
\GHI{10}

\subsection{Veit Schwämmle and Arthur Grimaud - Making sense of internal fragment ions}

Peptide identification from fragment mass spectra uses only part of the contained information. Here, internal fragment ions, i.e. peptides with both termini cleaved, have a high potential to provide further evidence about peptide identity. Despite the option to include internal ions in several database search engines, their actual use has so far been explored only poorly. A big challenge lies in the large number of possible ions, and thus the difficulty in distinguishing them from background signals or other fragment ions. This hackathon project aims to shed more light into the applicability of internal ions by creating a framework to determine their characteristic patterns in MS data. We will provide statistics and extensive visualizations for internal ions in a given data set. For that we will employ both raw data files and identifications from a database search. This framework will establish the grounds for the detection and utilization of characteristic internal ions in a dataset, explore potential “fragment motifs”, and facilitate the distinction of actual internal ions from background noise. A clearer understanding and exploration of internal fragmentation will channel future efforts towards a more extensive use of them in MS data processing leading to higher peptide identification rates.\\
\GHI{9}


\subsection{Tim Van Den Bossche - Exploring and solving functional analysis gaps in metaproteomics}

Metaproteomics, the study of the full protein complement of microbial communities, is becoming an increasingly popular approach to study microbiomes and is mostly combined with metagenomics or -transcriptomics. Although the latter approaches are more commonly used, they only reveal the potential functions of the microbiome. Metaproteomics, in contrast, reveals the actual functions of the microbiome because it studies the proteins, the worker molecules of the cell \citep{pmid32174200}. Specifically, these functions are described as functional annotations such as InterPro and GO terms, and these terms can often be mapped to functional pathways. Although this shows the added value of metaproteomics, there are still some major hurdles to take in optimizing the functional analyses of microbiomes. The input from the community will prove particularly useful here, as every lab or research group might have their own tools and therefore own problems in performing a functional analysis. This project will explore the challenges in the functional analyses of metaproteomics data, prioritize them, and undertake the first steps in solving the most urgent and technically feasible one. \GHI{7}

